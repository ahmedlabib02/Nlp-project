{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"authorship_tag":"ABX9TyMnw9EYMRvtCAVvsCBCKgcK","include_colab_link":true},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install datasets transformers\n","metadata":{"id":"dgLirjz0Dd0T","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:07:35.182435Z","iopub.execute_input":"2025-05-17T10:07:35.182933Z","iopub.status.idle":"2025-05-17T10:07:38.453284Z","shell.execute_reply.started":"2025-05-17T10:07:35.182913Z","shell.execute_reply":"2025-05-17T10:07:38.452269Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import PreTrainedTokenizerBase\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\nfrom transformers import TrainingArguments, Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:07:46.707344Z","iopub.execute_input":"2025-05-17T10:07:46.707965Z","iopub.status.idle":"2025-05-17T10:07:46.712209Z","shell.execute_reply.started":"2025-05-17T10:07:46.707936Z","shell.execute_reply":"2025-05-17T10:07:46.711243Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"squad = load_dataset(\"squad\")\nprint(squad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:07:51.083784Z","iopub.execute_input":"2025-05-17T10:07:51.084056Z","iopub.status.idle":"2025-05-17T10:07:53.325957Z","shell.execute_reply.started":"2025-05-17T10:07:51.084037Z","shell.execute_reply":"2025-05-17T10:07:53.325392Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 87599\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 10570\n    })\n})\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(squad[\"train\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:07:54.841688Z","iopub.execute_input":"2025-05-17T10:07:54.842305Z","iopub.status.idle":"2025-05-17T10:07:54.847052Z","shell.execute_reply.started":"2025-05-17T10:07:54.842282Z","shell.execute_reply":"2025-05-17T10:07:54.846206Z"}},"outputs":[{"name":"stdout","text":"{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"model_name = \"distilbert-base-uncased-distilled-squad\"\ntokenizer  = AutoTokenizer.from_pretrained(model_name)\nmodel_distilbert  = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:07:57.178658Z","iopub.execute_input":"2025-05-17T10:07:57.178927Z","iopub.status.idle":"2025-05-17T10:07:57.436809Z","shell.execute_reply.started":"2025-05-17T10:07:57.178908Z","shell.execute_reply":"2025-05-17T10:07:57.436226Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def preprocess(examples, tokenizer: PreTrainedTokenizerBase):\n    tokenized = tokenizer(\n        examples[\"question\"],\n        examples[\"context\"],\n        truncation=\"only_second\",\n        max_length=384,\n        stride=128,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized.pop(\"offset_mapping\")\n    start_positions = []\n    end_positions = []\n    for i, offsets in enumerate(offset_mapping):\n        sample_idx = sample_mapping[i]\n        answers = examples[\"answers\"][sample_idx]\n        seq_ids = tokenized.sequence_ids(i)\n        cls_index = 0\n        start_positions.append(cls_index)\n        end_positions.append(cls_index)\n        if len(answers[\"answer_start\"]) == 0:\n            continue\n        start_char = answers[\"answer_start\"][0]\n        end_char = start_char + len(answers[\"text\"][0])\n        context_tokens = [idx for idx, s_id in enumerate(seq_ids) if s_id == 1]\n        if not context_tokens:\n            continue\n        chunk_start_char = offsets[context_tokens[0]][0]\n        chunk_end_char = offsets[context_tokens[-1]][1]\n        if not (chunk_start_char <= start_char and end_char <= chunk_end_char):\n            continue\n        token_start_index = cls_index\n        token_end_index = cls_index\n        for idx in context_tokens:\n            off_start, off_end = offsets[idx]\n            if off_start <= start_char < off_end:\n                token_start_index = idx\n            if off_start < end_char <= off_end:\n                token_end_index = idx\n        start_positions[-1] = token_start_index\n        end_positions[-1] = token_end_index\n    tokenized[\"start_positions\"] = start_positions\n    tokenized[\"end_positions\"] = end_positions\n    return tokenized\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:07:59.981221Z","iopub.execute_input":"2025-05-17T10:07:59.981515Z","iopub.status.idle":"2025-05-17T10:07:59.989166Z","shell.execute_reply.started":"2025-05-17T10:07:59.981493Z","shell.execute_reply":"2025-05-17T10:07:59.988339Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"tokenized = squad.map(\n    lambda examples: preprocess(examples, tokenizer),\n    batched=True,\n    remove_columns=squad[\"train\"].column_names\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:08:02.631999Z","iopub.execute_input":"2025-05-17T10:08:02.632625Z","iopub.status.idle":"2025-05-17T10:08:07.929983Z","shell.execute_reply.started":"2025-05-17T10:08:02.632600Z","shell.execute_reply":"2025-05-17T10:08:07.928791Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3be663d3d668472d8309b3e0bf11549a"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"steps_per_epoch = len(tokenized[\"train\"]) // 64  \n\nargs = TrainingArguments(\n  output_dir=\"distilbert-qa\",\n  eval_steps=steps_per_epoch,\n  save_steps=steps_per_epoch,\n  per_device_train_batch_size=64,\n  per_device_eval_batch_size=64,\n  num_train_epochs=10,\n  learning_rate=3e-5,\n  weight_decay=0.01,\n  logging_steps=200,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:08:15.184610Z","iopub.execute_input":"2025-05-17T10:08:15.185208Z","iopub.status.idle":"2025-05-17T10:08:15.213116Z","shell.execute_reply.started":"2025-05-17T10:08:15.185182Z","shell.execute_reply":"2025-05-17T10:08:15.212556Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"trainer_full = Trainer(\n  model=model_distilbert,\n  args=args,\n  train_dataset=tokenized[\"train\"],\n  eval_dataset =tokenized[\"validation\"],\n  tokenizer=tokenizer,\n)\ntrainer_full.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T10:08:17.693554Z","iopub.execute_input":"2025-05-17T10:08:17.693824Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/277683205.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer_full = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null}]}