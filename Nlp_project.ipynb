{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedlabib02/Nlp-project/blob/main/Nlp_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhShSWMAHitF"
      },
      "source": [
        "# Milestone 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Unzipping the \"B Hodoo2\" channel folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_path = \"./B Hodoo2-20250226T182935Z-001.zip\"\n",
        "extract_path = \"./\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Unzipping the \"Kefaya ba2a\" channel folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_path = \"./Kefaya Ba2a-20250226T183527Z-001.zip\"\n",
        "extract_path = \"./\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Building dict for annotations and text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standardize(title):\n",
        "    \n",
        "    title = title.replace(\"_\", \" \")\n",
        "   \n",
        "    title = title.lower()\n",
        "    \n",
        "    title = re.sub(r'[^\\w\\s]', '', title)\n",
        "    \n",
        "    # title = re.sub(r'\\bبودكاست بهدوء مع كريم\\b', '', title)\n",
        "    # title = re.sub(r'\\bجلسة\\b', '', title)\n",
        "    \n",
        "    title = re.sub(r'\\s+', ' ', title).strip()\n",
        "    return title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_category_for_filename(target_filename, annotations_path):\n",
        "    \"\"\"\n",
        "    Load annotations from annotations_path and try to match the\n",
        "    canonicalized target_filename (without file extension) to the canonicalized\n",
        "    title from each annotation. If a match is found, return the annotation's category.\n",
        "    \"\"\"\n",
        "    with open(annotations_path, 'r', encoding='utf-8') as f_json:\n",
        "        annotations = json.load(f_json)\n",
        "    \n",
        "    base_target = os.path.splitext(target_filename)[0]\n",
        "    target_can = standardize(base_target)\n",
        "    for entry in annotations:\n",
        "        annotation_title = entry.get('title')\n",
        "        if annotation_title:\n",
        "            \n",
        "            annotation_can = standardize(annotation_title)\n",
        "            if annotation_can == target_can:\n",
        "                # print(\"Matched annotation:\", entry.get('title'))\n",
        "                return entry.get('category')\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_transcripts_from_folder(transcripts_dict, folder_path, channel):\n",
        "    \n",
        "    annotations_json = os.path.join(folder_path, 'annotations.json')\n",
        "    raw_folder = os.path.join(folder_path, 'raw')\n",
        "    for filename in os.listdir(raw_folder):\n",
        "        full_path = os.path.join(raw_folder, filename)\n",
        "        if os.path.isfile(full_path):\n",
        "            with open(full_path, 'r', encoding='utf-8') as file:\n",
        "                transcript = file.read()\n",
        "                category = get_category_for_filename(filename, annotations_json)\n",
        "            base_filename, _ = os.path.splitext(filename)\n",
        "            transcripts_dict[base_filename] = (channel, category, transcript)\n",
        "    return transcripts_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "transcripts_dict = {}\n",
        "first_folder_path = './B Hodoo2/'\n",
        "second_folder_path = './Kefaya Ba2a/'\n",
        "\n",
        "transcripts_dict = add_transcripts_from_folder(transcripts_dict, first_folder_path,  'B Hodoo2')\n",
        "transcripts_dict = add_transcripts_from_folder(transcripts_dict, second_folder_path, 'Kefaya Ba2a')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = [(title, info[0], info[1], info[2]) for title, info in transcripts_dict.items()]\n",
        "df = pd.DataFrame(data, columns=['title', 'channel', 'category', 'transcript'])\n",
        "print(df[0:1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'Education': 26, 'People & Blogs': 17, 'Comedy': 4})\n"
          ]
        }
      ],
      "source": [
        "category_counts = Counter(df['category'])\n",
        "print(category_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Since there are some entries without categories or an annotation file, we just remove them.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "df = df[df['category']!= None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exploring dataset size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47, 4)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    punctuations = string.punctuation + \"؟،؛«»…ـ\"  \n",
        "    translator = str.maketrans('', '', punctuations)\n",
        "    text = text.translate(translator)  \n",
        "    text = re.sub(r'[0-9A-Za-z]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "file_path = \"B Hodoo2/raw\\لماذا نيأس؟ عن فلسفة المثابرة _ بودكاست بهدوء مع كريم _ جلسة 20.txt\" \n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "print(clean_text(text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
