{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedlabib02/Nlp-project/blob/main/Nlp_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhShSWMAHitF"
      },
      "source": [
        "# Milestone 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\sana2\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os \n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import string\n",
        "from transformers import BertTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Unzipping the \"B Hodoo2\" channel folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_path = \"./B Hodoo2-20250226T182935Z-001.zip\"\n",
        "extract_path = \"./\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Unzipping the \"Kefaya ba2a\" channel folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_path = \"./Kefaya Ba2a-20250226T183527Z-001.zip\"\n",
        "extract_path = \"./\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Building dict for annotations and text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standardize(title):\n",
        "    \n",
        "    title = title.replace(\"_\", \" \")\n",
        "   \n",
        "    title = title.lower()\n",
        "    \n",
        "    title = re.sub(r'[^\\w\\s]', '', title)\n",
        "    \n",
        "    # title = re.sub(r'\\bبودكاست بهدوء مع كريم\\b', '', title)\n",
        "    # title = re.sub(r'\\bجلسة\\b', '', title)\n",
        "    \n",
        "    title = re.sub(r'\\s+', ' ', title).strip()\n",
        "    return title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_category_for_filename(target_filename, annotations_path):\n",
        "    \"\"\"\n",
        "    Load annotations from annotations_path and try to match the\n",
        "    canonicalized target_filename (without file extension) to the canonicalized\n",
        "    title from each annotation. If a match is found, return the annotation's category.\n",
        "    \"\"\"\n",
        "    with open(annotations_path, 'r', encoding='utf-8') as f_json:\n",
        "        annotations = json.load(f_json)\n",
        "    \n",
        "    base_target = os.path.splitext(target_filename)[0]\n",
        "    target_can = standardize(base_target)\n",
        "    for entry in annotations:\n",
        "        annotation_title = entry.get('title')\n",
        "        if annotation_title:\n",
        "            \n",
        "            annotation_can = standardize(annotation_title)\n",
        "            if annotation_can == target_can:\n",
        "                # print(\"Matched annotation:\", entry.get('title'))\n",
        "                return entry.get('category')\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_transcripts_from_folder(transcripts_dict, folder_path, channel):\n",
        "    \n",
        "    annotations_json = os.path.join(folder_path, 'annotations.json')\n",
        "    raw_folder = os.path.join(folder_path, 'raw')\n",
        "    for filename in os.listdir(raw_folder):\n",
        "        full_path = os.path.join(raw_folder, filename)\n",
        "        if os.path.isfile(full_path):\n",
        "            with open(full_path, 'r', encoding='utf-8') as file:\n",
        "                transcript = file.read()\n",
        "                category = get_category_for_filename(filename, annotations_json)\n",
        "            base_filename, _ = os.path.splitext(filename)\n",
        "            transcripts_dict[base_filename] = (channel, category, transcript)\n",
        "    return transcripts_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "transcripts_dict = {}\n",
        "first_folder_path = './B Hodoo2/'\n",
        "second_folder_path = './Kefaya Ba2a/'\n",
        "\n",
        "transcripts_dict = add_transcripts_from_folder(transcripts_dict, first_folder_path,  'B Hodoo2')\n",
        "transcripts_dict = add_transcripts_from_folder(transcripts_dict, second_folder_path, 'Kefaya Ba2a')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title   channel   category  \\\n",
            "0  أكبر كذبة في التاريخ _ وهم الانتاجية! - _ بودك...  B Hodoo2  Education   \n",
            "\n",
            "                                          transcript  \n",
            "0  النهارده الفيديو بتاعنا على\\nالانتاجيه لان الن...  \n"
          ]
        }
      ],
      "source": [
        "data = [(title, info[0], info[1], info[2]) for title, info in transcripts_dict.items()]\n",
        "df = pd.DataFrame(data, columns=['title', 'channel', 'category', 'transcript'])\n",
        "print(df[0:1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'Education': 26, 'People & Blogs': 17, 'Comedy': 4})\n"
          ]
        }
      ],
      "source": [
        "category_counts = Counter(df['category'])\n",
        "print(category_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Since there are some entries without categories or an annotation file, we just remove them.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "df = df[df['category']!= None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exploring dataset size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47, 4)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaning the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Removing numbers, non-Arabic letters and extra spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    punctuations = string.punctuation + \"؟،؛«»…ـ\"  \n",
        "    translator = str.maketrans('', '', punctuations)\n",
        "    text = text.translate(translator)  \n",
        "    text = re.sub(r'[0-9A-Za-z]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "file_path = \"B Hodoo2/raw\\لماذا نيأس؟ عن فلسفة المثابرة _ بودكاست بهدوء مع كريم _ جلسة 20.txt\" \n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "print(clean_text(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title   channel   category  \\\n",
            "0  أكبر كذبة في التاريخ _ وهم الانتاجية! - _ بودك...  B Hodoo2  Education   \n",
            "1  إزاي ضاعفت دخلي بدون شغل إضافي! - عن الرزق ووس...  B Hodoo2  Education   \n",
            "2  اخطر محتوى في العالم! _ بودكاست بهدوء مع كريم ...  B Hodoo2  Education   \n",
            "3  العيد والنكد - ليه مش بنبسط في العيد؟ _ بودكاس...  B Hodoo2  Education   \n",
            "4  انا فقير _ اصحابي كلهم أغنى مني! _ بودكاست بهد...  B Hodoo2  Education   \n",
            "\n",
            "                                          transcript  \n",
            "0  النهارده الفيديو بتاعنا على الانتاجيه لان النه...  \n",
            "1  انا النهارده جاي اقوللك ازاي تزود من دخلك الما...  \n",
            "2  النهارده انا جاي اتكلم على واحده من اخطر الظوا...  \n",
            "3  بصراحه انا موضوع ان احنا مش عارفين نتبسط في ال...  \n",
            "4  مساء الفل الفيديو ده عن الرزق لو انت واحد من ا...  \n"
          ]
        }
      ],
      "source": [
        "df[\"transcript\"] = df[\"transcript\"].apply(clean_text)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenization and Stop word removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     النهارده الفيديو بتاعنا على الانتاجيه لان النه...\n",
            "1     انا النهارده جاي اقوللك ازاي تزود من دخلك الما...\n",
            "2     النهارده انا جاي اتكلم على واحده من اخطر الظوا...\n",
            "3     بصراحه انا موضوع ان احنا مش عارفين نتبسط في ال...\n",
            "4     مساء الفل الفيديو ده عن الرزق لو انت واحد من ا...\n",
            "5     الفيديو ده ثقيل جدا على قلبي وللاسف الفيديو ده...\n",
            "6     عندنا في مصر لما بيبقى في حد الدنيا مخبطه معاه...\n",
            "7     مافيش حد فينا الا وفي حياته نسبه من القلق سواء...\n",
            "8     يدخل البيت فبيقول لها وصفي لي الحرامي بوليس بق...\n",
            "9     النهارده انا جاي اكلمك في موضوع في منتهى الخطو...\n",
            "10    الحلقه دي بقى بالذات انا دايما يا جماعه زي ما ...\n",
            "11    من حوالي سبع سنين واحده كتبت لي في التعليقات ي...\n",
            "12    السلام عليكم ورحمه انت ازاي تدخل عليا بوكاس كد...\n",
            "13    اول يا جماعه لما بتقول الله هو من فعل بذلك الن...\n",
            "14    طبعا كالعاده احنا اتعودنا ان اي فيديو يبدا لاز...\n",
            "15    النهارده انا بهدي الحلقه دي لنفسي اولا والله ب...\n",
            "16    ينفع اشارككم حاجه بدون مثاليه عاليه ومبالغات ب...\n",
            "17    وكالعاده مستمرين في التمرد على الغوريزم ولو مح...\n",
            "18    اهلا وسهلا بكم في الجزء التاني من تسع نصائح نف...\n",
            "19    الحمد لله ان وقع عل سقف البيت والله دي قصه حقي...\n",
            "20    واحده من اكتر الحاجات اللي ممكن تضايق الانسان ...\n",
            "21    الله يعزكم يا رب دوري ده ولا ايه بسم الله طيب ...\n",
            "22    تساؤل قريته على الفيسبوك عليه اكتر من شير في ا...\n",
            "23    ما علينا ه منتج يا باولو والله العظيم انت شويه...\n",
            "24    تقريبا مفيش حد فينا وهو صغير ما شفش في التلفزي...\n",
            "25    بيقولوا الانسان قوي لما بيوصل سن الثلاثين بيشو...\n",
            "26    السلام عليكم ورحمه الله وبركاته دي نصائح التلا...\n",
            "27    موسيقى انت فكرنا فين السيز احنا محتاجين الكفاي...\n",
            "28    اهلا بكم مره اخرى في بودكاست المفضل كفايه بقى ...\n",
            "29    موسيقى اهلا بكم في بودكاست كفايه بقى البودكاست...\n",
            "30    موسيقى اهلا بكم في بودكاست كفايه بقى البودكاست...\n",
            "31    اهلا بكم في بودكاست كفايه بقى البودكاست ده يا ...\n",
            "32    اهلا بكم في بودكاست كفايه بقى البودكاست ده يا ...\n",
            "33    اهلا بكم في بودكاست كفايه بقى البودكاست ده يا ...\n",
            "34    موسيقى اهلا بكم في بودكاست كفايه بقى البودكاست...\n",
            "35    موسيقى اهلا بكم في بودكاست كفايه بقى البودكاست...\n",
            "36    اهلا بكم في بودكاست كفايه بقى البودكاست ده يا ...\n",
            "37    موسيقى اهلا بكم في بودكاست كفايه بقى البودكاست...\n",
            "38    اهلا بكم في بودكاست كفايه بقى البودكاست ده يا ...\n",
            "39    موسيقى اهلا بكم في بودكاست كفايه بقى النسخه ال...\n",
            "40    اهلا بكم في بودكاست كفايه بقى النسخه الرمضانيه...\n",
            "41    اهلا بكم في بودكاست كفايه بقى النسخه الرمضانيه...\n",
            "42    اهلا بكم في بودكاست كفايه بقى النسخه الرمضانيه...\n",
            "43    اهلا بكم في بودكاست كفايه بقى النسخه الرمضانيه...\n",
            "44    اهلا بكم في بودكاست كفايه بقى النسخه الرمضانيه...\n",
            "45    اهلا بكم في بودكاست كفايه بقى النسخه الرمضانيه...\n",
            "46    اهلا بكم في بودكاست كفايه بقى النسخه الرمضانيه...\n",
            "47    اهلا بكم في بودكاست كفايه بقى البودكاست ده يا ...\n",
            "Name: transcript, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df['transcript'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "def tokenize(df):\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "    df['transcript'] = df['transcript'].apply(lambda x: tokenizer.tokenize(str(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "tokenize(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           transcript\n",
            "0   [ال, ##نها, ##رد, ##ه, ال, ##فيد, ##يو, ب, ##ت...\n",
            "1   [ان, ##ا, ال, ##نها, ##رد, ##ه, جا, ##ي, ا, ##...\n",
            "2   [ال, ##نها, ##رد, ##ه, ان, ##ا, جا, ##ي, ا, ##...\n",
            "3   [ب, ##صر, ##اح, ##ه, ان, ##ا, موضوع, ان, ا, ##...\n",
            "4   [م, ##ساء, ال, ##فل, ال, ##فيد, ##يو, ده, عن, ...\n",
            "5   [ال, ##فيد, ##يو, ده, ث, ##قيل, جدا, على, قلب,...\n",
            "6   [عند, ##نا, في, مصر, لما, بي, ##بقى, في, حد, ا...\n",
            "7   [ما, ##في, ##ش, حد, في, ##نا, ال, ##ا, وفي, حي...\n",
            "8   [يد, ##خل, ال, ##بيت, ف, ##بي, ##قول, لها, وصف...\n",
            "9   [ال, ##نها, ##رد, ##ه, ان, ##ا, جا, ##ي, ا, ##...\n",
            "10  [ال, ##حل, ##قه, دي, ب, ##قى, با, ##ل, ##ذا, #...\n",
            "11  [من, حوالي, سب, ##ع, سن, ##ين, واحد, ##ه, كتب,...\n",
            "12  [السلام, علي, ##كم, و, ##رح, ##مه, ان, ##ت, از...\n",
            "13  [اول, يا, ج, ##ماع, ##ه, لما, ب, ##ت, ##قول, ا...\n",
            "14  [ط, ##بع, ##ا, ك, ##ال, ##عاد, ##ه, ا, ##حن, #...\n",
            "15  [ال, ##نها, ##رد, ##ه, ان, ##ا, به, ##دي, ال, ...\n",
            "16  [ي, ##نف, ##ع, اش, ##ارك, ##كم, ح, ##اج, ##ه, ...\n",
            "17  [و, ##كا, ##ل, ##عاد, ##ه, م, ##ست, ##مر, ##ين...\n",
            "18  [اهل, ##ا, و, ##سه, ##لا, ب, ##كم, في, الجزء, ...\n",
            "19  [ال, ##حمد, ل, ##له, ان, و, ##قع, ع, ##ل, س, #...\n",
            "20  [واحد, ##ه, من, ا, ##ك, ##تر, ال, ##ح, ##اجات,...\n",
            "21  [الله, ي, ##ع, ##ز, ##كم, يا, ر, ##ب, دوري, ده...\n",
            "22  [ت, ##سا, ##ؤ, ##ل, ق, ##ري, ##ته, على, ال, ##...\n",
            "23  [ما, علي, ##نا, ه, من, ##تج, يا, با, ##ول, ##و...\n",
            "24  [ت, ##قر, ##يبا, م, ##في, ##ش, حد, في, ##نا, و...\n",
            "25  [بي, ##قول, ##وا, ال, ##انس, ##ان, ق, ##وي, لم...\n",
            "26  [السلام, علي, ##كم, و, ##رح, ##مه, الله, وب, #...\n",
            "27  [م, ##وسيقى, ان, ##ت, ف, ##كر, ##نا, في, ##ن, ...\n",
            "28  [اهل, ##ا, ب, ##كم, م, ##ره, ا, ##خرى, في, بود...\n",
            "29  [م, ##وسيقى, اهل, ##ا, ب, ##كم, في, بود, ##كا,...\n",
            "30  [م, ##وسيقى, اهل, ##ا, ب, ##كم, في, بود, ##كا,...\n",
            "31  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "32  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "33  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "34  [م, ##وسيقى, اهل, ##ا, ب, ##كم, في, بود, ##كا,...\n",
            "35  [م, ##وسيقى, اهل, ##ا, ب, ##كم, في, بود, ##كا,...\n",
            "36  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "37  [م, ##وسيقى, اهل, ##ا, ب, ##كم, في, بود, ##كا,...\n",
            "38  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "39  [م, ##وسيقى, اهل, ##ا, ب, ##كم, في, بود, ##كا,...\n",
            "40  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "41  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "42  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "43  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "44  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "45  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "46  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n",
            "47  [اهل, ##ا, ب, ##كم, في, بود, ##كا, ##ست, ك, ##...\n"
          ]
        }
      ],
      "source": [
        "print(df[[ 'transcript']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "arabic_stopwords = set(stopwords.words('arabic'))\n",
        "def remove_stopwords(tokens):\n",
        "    return [token for token in tokens if token not in arabic_stopwords]\n",
        "\n",
        "df['transcript'] = df['transcript'].apply(remove_stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     [ال, ##نها, ##رد, ##ه, ال, ##فيد, ##يو, ##تا, ...\n",
              "1     [ان, ##ا, ال, ##نها, ##رد, ##ه, جا, ##ي, ##قول...\n",
              "2     [ال, ##نها, ##رد, ##ه, ان, ##ا, جا, ##ي, ##ت, ...\n",
              "3     [##صر, ##اح, ##ه, ان, ##ا, موضوع, ان, ##حن, ##...\n",
              "4     [##ساء, ال, ##فل, ال, ##فيد, ##يو, ده, ال, ##ر...\n",
              "5     [ال, ##فيد, ##يو, ده, ##قيل, جدا, قلب, ##ي, ##...\n",
              "6     [##نا, مصر, ##بقى, حد, ال, ##دن, ##يا, ##خ, ##...\n",
              "7     [##في, ##ش, حد, ##نا, ال, ##ا, وفي, حياته, ##س...\n",
              "8     [يد, ##خل, ال, ##بيت, ##بي, ##قول, وصف, ##ي, ا...\n",
              "9     [ال, ##نها, ##رد, ##ه, ان, ##ا, جا, ##ي, ##كل,...\n",
              "10    [ال, ##حل, ##قه, دي, ##قى, با, ##ل, ##ذا, ##ت,...\n",
              "11    [حوالي, سب, ##ع, سن, ##ين, ##ه, كتب, ##ت, ال, ...\n",
              "12    [السلام, علي, ##كم, ##رح, ##مه, ان, ##ت, از, #...\n",
              "13    [اول, ##ماع, ##ه, ##ت, ##قول, الله, فعل, بذلك,...\n",
              "14    [##بع, ##ا, ##ال, ##عاد, ##ه, ##حن, ##ا, ##ت, ...\n",
              "15    [ال, ##نها, ##رد, ##ه, ان, ##ا, ##دي, ال, ##حل...\n",
              "16    [##نف, ##ع, اش, ##ارك, ##كم, ##اج, ##ه, بدون, ...\n",
              "17    [##كا, ##ل, ##عاد, ##ه, ##ست, ##مر, ##ين, ال, ...\n",
              "18    [اهل, ##ا, ##سه, ##لا, ##كم, الجزء, ال, ##تان,...\n",
              "19    [ال, ##حمد, ##له, ان, ##قع, ##ل, ##قف, ال, ##ب...\n",
              "20    [##ه, ##ك, ##تر, ال, ##ح, ##اجات, ال, ##لي, ##...\n",
              "21    [الله, ##ع, ##ز, ##كم, ##ب, دوري, ده, ##يه, ##...\n",
              "22    [##سا, ##ؤ, ##ل, ##ري, ##ته, ال, ##في, ##سب, #...\n",
              "23    [علي, ##نا, ##تج, با, ##ول, ##و, ##الله, ال, #...\n",
              "24    [##قر, ##يبا, ##في, ##ش, حد, ##نا, ##غير, ##ف,...\n",
              "25    [##قول, ##وا, ال, ##انس, ##ان, ##وي, ##و, ##صل...\n",
              "26    [السلام, علي, ##كم, ##رح, ##مه, الله, وب, ##رك...\n",
              "27    [##وسيقى, ان, ##ت, ##كر, ##نا, ##ن, ال, ##سي, ...\n",
              "28    [اهل, ##ا, ##كم, ##ره, ##خرى, بود, ##كا, ##ست,...\n",
              "29    [##وسيقى, اهل, ##ا, ##كم, بود, ##كا, ##ست, ##ف...\n",
              "30    [##وسيقى, اهل, ##ا, ##كم, بود, ##كا, ##ست, ##ف...\n",
              "31    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "32    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "33    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "34    [##وسيقى, اهل, ##ا, ##كم, بود, ##كا, ##ست, ##ف...\n",
              "35    [##وسيقى, اهل, ##ا, ##كم, بود, ##كا, ##ست, ##ف...\n",
              "36    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "37    [##وسيقى, اهل, ##ا, ##كم, بود, ##كا, ##ست, ##ف...\n",
              "38    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "39    [##وسيقى, اهل, ##ا, ##كم, بود, ##كا, ##ست, ##ف...\n",
              "40    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "41    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "42    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "43    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "44    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "45    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "46    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "47    [اهل, ##ا, ##كم, بود, ##كا, ##ست, ##فا, ##يه, ...\n",
              "Name: transcript, dtype: object"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['transcript']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
