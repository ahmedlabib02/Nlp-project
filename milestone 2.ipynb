{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNMvLH9BB7pR"
      },
      "source": [
        "# Milestone 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import os, zipfile , json , random, requests\n",
        "import re\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "kFomRI3xB9d8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explorting dataset:"
      ],
      "metadata": {
        "id": "1zzFTlcTCEc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq41oiX90fQq",
        "outputId": "3a7ec2d3-6ee1-4e7d-b2ab-691efd6f5f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dir = '/content/drive/MyDrive/SQuAD'\n",
        "os.makedirs(drive_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "e0NuNGE435ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = os.path.join(drive_dir, 'train-v2.0.json')"
      ],
      "metadata": {
        "id": "TSDZT50PX9sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    squad = json.load(f)"
      ],
      "metadata": {
        "id": "s_tEP-KyHMFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records = []\n",
        "for article in squad['data']:\n",
        "    for para in article['paragraphs']:\n",
        "        ctx = para['context']\n",
        "        for qa in para['qas']:\n",
        "            answers = [a['text'] for a in qa.get('answers', [])]\n",
        "            starts  = [a['answer_start'] for a in qa.get('answers', [])]\n",
        "            ends    = [s + len(t) for s,t in zip(starts, answers)]\n",
        "            records.append({\n",
        "                'question': qa['question'],\n",
        "                'answers': answers,\n",
        "                'context': ctx,\n",
        "                'answer_start': starts,\n",
        "                'answer_end': ends\n",
        "            })\n",
        "\n"
      ],
      "metadata": {
        "id": "JixYG4s6saGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(records)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NhZlSX4qtmtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random.shuffle(examples)\n",
        "#subset = examples[:15000]\n",
        "#len(subset)\n",
        "print(\"Total QA pairs:\", len(df))"
      ],
      "metadata": {
        "id": "D72WTTHOupEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffling\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# only working on subset of 15k row\n",
        "df_subset = df.head(15000).copy().reset_index(drop=True)\n",
        "\n",
        "print(\"Subset size:\", df_subset.shape)\n",
        "df_subset.head()"
      ],
      "metadata": {
        "id": "rSzBSJjsx1MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Cleaning"
      ],
      "metadata": {
        "id": "-EdBrPmqbBvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping rows where answers are empty"
      ],
      "metadata": {
        "id": "E_Cb25_x11aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df_subset[df_subset['answers'].map(len) > 0].reset_index(drop=True)\n",
        "print(\"Rows remaining after drop:\", len(df))"
      ],
      "metadata": {
        "id": "JCoQdBYJ19ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Extra Whitespaces"
      ],
      "metadata": {
        "id": "QBSLXMvASpe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collapse_whitespace(s):\n",
        "    if isinstance(s, str):\n",
        "        return re.sub(r'\\s+', ' ', s.strip())\n",
        "    return s"
      ],
      "metadata": {
        "id": "FZAnlrcyStOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['question', 'context', 'answers']:\n",
        "    if col in df_subset.columns:\n",
        "        df_subset[col] = df_subset[col].apply(collapse_whitespace)"
      ],
      "metadata": {
        "id": "fnVh34G5VBAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lets explore the length of the sequences which will determine some hyperparameters in training the models**"
      ],
      "metadata": {
        "id": "JFeXiO2dzf8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset['question'].str.len().max()"
      ],
      "metadata": {
        "id": "Lc530Af3zoTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset['context'].str.len().max()"
      ],
      "metadata": {
        "id": "dDvLl2vx0a4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mult = df[df['answers'].map(len) > 1].reset_index(drop=True)\n",
        "print(\"Rows with multiple answers:\", df_mult.shape[0])\n",
        "display(df_mult[['question', 'answers', 'answer_start', 'answer_end']].head())"
      ],
      "metadata": {
        "id": "oFELaKp400ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just turn the array of the answers to a string since none have multiple answers"
      ],
      "metadata": {
        "id": "6hWOoWFg1GZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset['answers']= df_subset['answers'].apply(lambda x: x[0])"
      ],
      "metadata": {
        "id": "rh00m5Jw0lWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset['answers'].str.len().max()"
      ],
      "metadata": {
        "id": "WoL1ZTTx0z8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "B_-pDASk5eOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet gensim"
      ],
      "metadata": {
        "id": "gBEVZxrJ5gav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_texts = (\n",
        "    df_subset['question'].tolist() +\n",
        "    df_subset['context'].tolist() +\n",
        "    df_subset['answers'].tolist()\n",
        ")\n",
        "tokenizer = Tokenizer(\n",
        "    num_words=20000,\n",
        "    oov_token='[UNK]',\n",
        "    filters='''!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'''\n",
        ")\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "q_seqs = tokenizer.texts_to_sequences(df['question'])\n",
        "c_seqs = tokenizer.texts_to_sequences(df['context'])\n",
        "a_seqs = tokenizer.texts_to_sequences(df['answers'])"
      ],
      "metadata": {
        "id": "l2U-kh4D5mdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)\n",
        "print(\"Total unique tokens:\", vocab_size)\n"
      ],
      "metadata": {
        "id": "KnOdBzFlWfhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_seqs[0]"
      ],
      "metadata": {
        "id": "_PX28kds7kK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load gloVe dictionary**"
      ],
      "metadata": {
        "id": "bEwBdMqoGBO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dir = '/content/drive/MyDrive/glove'\n",
        "os.makedirs(drive_dir, exist_ok=True)\n",
        "zip_path = os.path.join(drive_dir, 'glove.6B.zip')\n",
        "glove_path = os.path.join(drive_dir, 'glove.6B.100d.txt')\n",
        "\n",
        "if not os.path.exists(glove_path):\n",
        "    if not os.path.exists(zip_path):\n",
        "        url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "        with requests.get(url, stream=True) as r, open(zip_path, 'wb') as f:\n",
        "            for chunk in r.iter_content(8192):\n",
        "                f.write(chunk)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extract('glove.6B.100d.txt', path=drive_dir)\n",
        "print(f\"GloVe ready at {glove_path}\")\n"
      ],
      "metadata": {
        "id": "sHHCMrjhGG4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating embeddings index (mapping words to vectors)**"
      ],
      "metadata": {
        "id": "moKmgC0MGTU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        parts = line.rstrip().split(\" \")\n",
        "        word = parts[0]\n",
        "        vec  = np.asarray(parts[1:], dtype='float32')\n",
        "        embeddings_index[word] = vec"
      ],
      "metadata": {
        "id": "3cSrFo3eGdH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating our look-up table (embedding matrix)**"
      ],
      "metadata": {
        "id": "DWBBEfnDHXhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "emb_dim = 100\n",
        "embedding_matrix = np.random.normal(size=(vocab_size, emb_dim)) * 0.01"
      ],
      "metadata": {
        "id": "KNj69dr19Io_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, idx in tokenizer.word_index.items():\n",
        "    if idx >= vocab_size:\n",
        "        continue\n",
        "    if word in embeddings_index:\n",
        "        embedding_matrix[idx] = embeddings_index[word]"
      ],
      "metadata": {
        "id": "5OFnRaWp_DsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = tokenizer.index_word[2]\n",
        "print(word)\n",
        "print(embedding_matrix[2])"
      ],
      "metadata": {
        "id": "IkAwXryuJNZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create embedding layer**"
      ],
      "metadata": {
        "id": "fXmVw1ItJ-uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=emb_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False,\n",
        "    name='glove_embedding'\n",
        ")"
      ],
      "metadata": {
        "id": "FVUoVwpZJPMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Phase One"
      ],
      "metadata": {
        "id": "Ci0NXaY-UBOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_Q_LEN   = df_subset['question'].str.len().max()\n",
        "MAX_A_LEN   = df_subset['answers'].str.len().max()\n",
        "VOCAB_SIZE  = len(tokenizer.word_index) + 1\n",
        "EMB_DIM     = embedding_matrix.shape[1]\n",
        "UNITS       = 128\n",
        "BATCH_SIZE  = 64\n",
        "EPOCHS      = 30"
      ],
      "metadata": {
        "id": "XSOJYRpOKaqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenizer.word_index))"
      ],
      "metadata": {
        "id": "IPAwA_cONrNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_padded = pad_sequences(q_seqs, maxlen=MAX_Q_LEN, padding='post', truncating='post')\n",
        "a_padded = pad_sequences(a_seqs, maxlen=MAX_A_LEN, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "JERoPRt-RHlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input  = a_padded[:, :-1]\n",
        "decoder_target = a_padded[:, 1:]\n",
        "\n",
        "Xq_tr, Xq_val, Din_tr, Din_val, Dt_tr, Dt_val = train_test_split(\n",
        "    q_padded, decoder_input, decoder_target,\n",
        "    test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "def make_ds(q, d_in, d_tar, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(((q, d_in), d_tar))\n",
        "    return ds.shuffle(2000).batch(batch_size).prefetch(1)\n",
        "\n",
        "train_ds = make_ds(Xq_tr, Din_tr, Dt_tr)\n",
        "val_ds   = make_ds(Xq_val, Din_val, Dt_val)"
      ],
      "metadata": {
        "id": "zaezBfWvSmaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building encoder**"
      ],
      "metadata": {
        "id": "5weJ2zRowLv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(MAX_Q_LEN,), batch_size= BATCH_SIZE, name='encoder_input')\n",
        "enc_embedded   = embedding_layer(encoder_inputs)                # (batch, Q, emb_dim)\n",
        "_, state_h, state_c = LSTM(UNITS, return_state=True, name='encoder_lstm')(enc_embedded)\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "S22udvdjTV02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building encoder**"
      ],
      "metadata": {
        "id": "FG4qYrFIwQuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs= Input(shape=(MAX_A_LEN-1,), batch_size=BATCH_SIZE ,name='decoder_input')\n",
        "dec_embedded= embedding_layer(decoder_inputs)\n",
        "dec_lstm = LSTM(UNITS, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "dec_outputs, _, _ = dec_lstm(dec_embedded, initial_state=encoder_states)\n",
        "decoder_dense   = Dense(vocab_size, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(dec_outputs)"
      ],
      "metadata": {
        "id": "vZY_L0M1T0j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the model**"
      ],
      "metadata": {
        "id": "s-DjaB2H1448"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "vGm4vS0uUC-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0Ob7b0rFUGIU",
        "outputId": "da2f99bc-75c8-4de9-cde0-6c9f97ac17e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-11c2b8463d60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36vdUH2M4TGY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}