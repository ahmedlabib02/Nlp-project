{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11489407,"sourceType":"datasetVersion","datasetId":7201839}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Milestone 2","metadata":{"id":"qNMvLH9BB7pR"}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport pandas as pd\nimport os, zipfile , json , random, requests\nimport re\nfrom pathlib import Path\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import Input, LSTM, Dense\nfrom tensorflow.keras.models import Model","metadata":{"id":"kFomRI3xB9d8","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:47:31.793998Z","iopub.execute_input":"2025-04-20T17:47:31.794482Z","iopub.status.idle":"2025-04-20T17:47:31.799324Z","shell.execute_reply.started":"2025-04-20T17:47:31.794459Z","shell.execute_reply":"2025-04-20T17:47:31.798544Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Explorting dataset:","metadata":{"id":"1zzFTlcTCEc7"}},{"cell_type":"code","source":"\ndef is_kaggle():\n    # Kaggle kernels always set this env var\n    return 'KAGGLE_URL_BASE' in os.environ\n\ndef is_colab():\n    return (not is_kaggle()) and os.path.exists('/content')\n\ndef maybe_mount_drive():\n    if is_colab():\n        from google.colab import drive\n        if not os.path.isdir('/content/drive'):\n            drive.mount('/content/drive')\n\ndef get_data_path():\n    if is_kaggle():\n        return '/kaggle/input/squad-2-0/'\n    elif is_colab():\n        return '/content/drive/MyDrive/SQuAD'\n    else:\n        return './data/'\ndef get_model_dir():\n    if is_colab():\n        model_dir = '/content/drive/MyDrive/models'\n    elif is_kaggle():\n        model_dir = '/kaggle/working/models'\n    else:\n        model_dir = './models'\n    os.makedirs(model_dir, exist_ok=True)\n    return model_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:03:37.635598Z","iopub.execute_input":"2025-04-20T18:03:37.635900Z","iopub.status.idle":"2025-04-20T18:03:37.641863Z","shell.execute_reply.started":"2025-04-20T18:03:37.635880Z","shell.execute_reply":"2025-04-20T18:03:37.641096Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"dataset_dir = get_data_path()\nmaybe_mount_drive()\nos.makedirs(dataset_dir, exist_ok=True)","metadata":{"id":"e0NuNGE435ad","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:47:36.478211Z","iopub.execute_input":"2025-04-20T17:47:36.478478Z","iopub.status.idle":"2025-04-20T17:47:36.482897Z","shell.execute_reply.started":"2025-04-20T17:47:36.478458Z","shell.execute_reply":"2025-04-20T17:47:36.482159Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"file_path = os.path.join(dataset_dir, 'train-v2.0.json')","metadata":{"id":"TSDZT50PX9sj","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:47:37.331610Z","iopub.execute_input":"2025-04-20T17:47:37.332442Z","iopub.status.idle":"2025-04-20T17:47:37.335885Z","shell.execute_reply.started":"2025-04-20T17:47:37.332412Z","shell.execute_reply":"2025-04-20T17:47:37.335107Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"with open(file_path, 'r', encoding='utf-8') as f:\n    squad = json.load(f)","metadata":{"id":"s_tEP-KyHMFT","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:47:38.624432Z","iopub.execute_input":"2025-04-20T17:47:38.625011Z","iopub.status.idle":"2025-04-20T17:47:39.805096Z","shell.execute_reply.started":"2025-04-20T17:47:38.624988Z","shell.execute_reply":"2025-04-20T17:47:39.804295Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"records = []\nfor article in squad['data']:\n    for para in article['paragraphs']:\n        ctx = para['context']\n        for qa in para['qas']:\n            answers = [a['text'] for a in qa.get('answers', [])]\n            starts  = [a['answer_start'] for a in qa.get('answers', [])]\n            ends    = [s + len(t) for s,t in zip(starts, answers)]\n            records.append({\n                'question': qa['question'],\n                'answers': answers,\n                'context': ctx,\n                'answer_start': starts,\n                'answer_end': ends\n            })\n\n","metadata":{"id":"JixYG4s6saGU","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:46:44.931828Z","iopub.execute_input":"2025-04-20T18:46:44.932500Z","iopub.status.idle":"2025-04-20T18:46:46.057092Z","shell.execute_reply.started":"2025-04-20T18:46:44.932476Z","shell.execute_reply":"2025-04-20T18:46:46.056511Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"df = pd.DataFrame(records)\ndf.head()","metadata":{"id":"NhZlSX4qtmtj","outputId":"96567ffd-6526-4218-c322-84c26cd2e7e6","colab":{"base_uri":"https://localhost:8080/","height":206},"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:46:47.119431Z","iopub.execute_input":"2025-04-20T18:46:47.119929Z","iopub.status.idle":"2025-04-20T18:46:47.251828Z","shell.execute_reply.started":"2025-04-20T18:46:47.119909Z","shell.execute_reply":"2025-04-20T18:46:47.251034Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"                                            question                answers  \\\n0           When did Beyonce start becoming popular?    [in the late 1990s]   \n1  What areas did Beyonce compete in when she was...  [singing and dancing]   \n2  When did Beyonce leave Destiny's Child and bec...                 [2003]   \n3      In what city and state did Beyonce  grow up?        [Houston, Texas]   \n4         In which decade did Beyonce become famous?           [late 1990s]   \n\n                                             context answer_start answer_end  \n0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...        [269]      [286]  \n1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...        [207]      [226]  \n2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...        [526]      [530]  \n3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...        [166]      [180]  \n4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...        [276]      [286]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answers</th>\n      <th>context</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>When did Beyonce start becoming popular?</td>\n      <td>[in the late 1990s]</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>[269]</td>\n      <td>[286]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What areas did Beyonce compete in when she was...</td>\n      <td>[singing and dancing]</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>[207]</td>\n      <td>[226]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>When did Beyonce leave Destiny's Child and bec...</td>\n      <td>[2003]</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>[526]</td>\n      <td>[530]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In what city and state did Beyonce  grow up?</td>\n      <td>[Houston, Texas]</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>[166]</td>\n      <td>[180]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>In which decade did Beyonce become famous?</td>\n      <td>[late 1990s]</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>[276]</td>\n      <td>[286]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"print(\"Total QA pairs:\", len(df))","metadata":{"id":"D72WTTHOupEF","outputId":"6686b957-2f37-44bc-c831-47864e7260dd","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:46:49.441846Z","iopub.execute_input":"2025-04-20T18:46:49.442399Z","iopub.status.idle":"2025-04-20T18:46:49.445963Z","shell.execute_reply.started":"2025-04-20T18:46:49.442375Z","shell.execute_reply":"2025-04-20T18:46:49.445283Z"}},"outputs":[{"name":"stdout","text":"Total QA pairs: 130319\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"#shuffling\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# only working on subset of 15k row\ndf_subset = df.head(15000).copy().reset_index(drop=True)\n\nprint(\"Subset size:\", df_subset.shape)\ndf_subset.head()","metadata":{"id":"rSzBSJjsx1MU","outputId":"97a3a6d3-c217-4ab8-a1b7-edd234dca397","colab":{"base_uri":"https://localhost:8080/","height":310},"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:46:51.026026Z","iopub.execute_input":"2025-04-20T18:46:51.026556Z","iopub.status.idle":"2025-04-20T18:46:51.110044Z","shell.execute_reply.started":"2025-04-20T18:46:51.026533Z","shell.execute_reply":"2025-04-20T18:46:51.109348Z"}},"outputs":[{"name":"stdout","text":"Subset size: (15000, 5)\n","output_type":"stream"},{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  What year did the global recession that follow...   \n1  what was a popular club in ibiza that started ...   \n2  In what century did Martin Luther honor Mary a...   \n3                          What is the climate like?   \n4        How many times has the Queen toured Canada?   \n\n                                   answers  \\\n0                                   [2012]   \n1                                [Amnesia]   \n2                                       []   \n3  [varies from hot and subhumid tropical]   \n4                                       []   \n\n                                             context answer_start answer_end  \n0  It threatened the collapse of large financial ...        [481]      [485]  \n1  But house was also being developed on Ibiza,[c...        [251]      [258]  \n2  Although Calvin and Huldrych Zwingli honored M...           []         []  \n3  Due to extreme variation in elevation, great v...        [115]      [152]  \n4  The Queen addressed the United Nations for a s...           []         []  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answers</th>\n      <th>context</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What year did the global recession that follow...</td>\n      <td>[2012]</td>\n      <td>It threatened the collapse of large financial ...</td>\n      <td>[481]</td>\n      <td>[485]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>what was a popular club in ibiza that started ...</td>\n      <td>[Amnesia]</td>\n      <td>But house was also being developed on Ibiza,[c...</td>\n      <td>[251]</td>\n      <td>[258]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>In what century did Martin Luther honor Mary a...</td>\n      <td>[]</td>\n      <td>Although Calvin and Huldrych Zwingli honored M...</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the climate like?</td>\n      <td>[varies from hot and subhumid tropical]</td>\n      <td>Due to extreme variation in elevation, great v...</td>\n      <td>[115]</td>\n      <td>[152]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How many times has the Queen toured Canada?</td>\n      <td>[]</td>\n      <td>The Queen addressed the United Nations for a s...</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":95},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{"id":"-EdBrPmqbBvA"}},{"cell_type":"markdown","source":"Dropping rows where answers are empty","metadata":{"id":"E_Cb25_x11aT"}},{"cell_type":"code","source":"df_subset = df_subset[df_subset['answers'].map(len) > 0].reset_index(drop=True)\nprint(\"Rows remaining after drop:\", len(df_subset))","metadata":{"id":"JCoQdBYJ19ON","colab":{"base_uri":"https://localhost:8080/"},"outputId":"98bfb707-f5f5-4339-8879-dd7c8426a6d9","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:46:54.974142Z","iopub.execute_input":"2025-04-20T18:46:54.974630Z","iopub.status.idle":"2025-04-20T18:46:54.989783Z","shell.execute_reply.started":"2025-04-20T18:46:54.974607Z","shell.execute_reply":"2025-04-20T18:46:54.989042Z"}},"outputs":[{"name":"stdout","text":"Rows remaining after drop: 10020\n","output_type":"stream"}],"execution_count":96},{"cell_type":"markdown","source":"Removing Extra Whitespaces","metadata":{"id":"QBSLXMvASpe0"}},{"cell_type":"code","source":"def collapse_whitespace(s):\n    if isinstance(s, str):\n        return re.sub(r'\\s+', ' ', s.strip())\n    return s","metadata":{"id":"FZAnlrcyStOE","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:46:57.720427Z","iopub.execute_input":"2025-04-20T18:46:57.720718Z","iopub.status.idle":"2025-04-20T18:46:57.724745Z","shell.execute_reply.started":"2025-04-20T18:46:57.720698Z","shell.execute_reply":"2025-04-20T18:46:57.724000Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"for col in ['question', 'context', 'answers']:\n    if col in df_subset.columns:\n        df_subset[col] = df_subset[col].apply(collapse_whitespace)","metadata":{"id":"fnVh34G5VBAm","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:46:59.880861Z","iopub.execute_input":"2025-04-20T18:46:59.881145Z","iopub.status.idle":"2025-04-20T18:47:00.359546Z","shell.execute_reply.started":"2025-04-20T18:46:59.881123Z","shell.execute_reply":"2025-04-20T18:47:00.358869Z"}},"outputs":[],"execution_count":98},{"cell_type":"markdown","source":"**Lets explore the length of the sequences which will determine some hyperparameters in training the models**","metadata":{"id":"JFeXiO2dzf8Q"}},{"cell_type":"code","source":"df_subset['question'].str.len().max()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lc530Af3zoTV","outputId":"f93ee1cc-11ca-4548-ea54-98ddafec6e05","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:02.827341Z","iopub.execute_input":"2025-04-20T18:47:02.827581Z","iopub.status.idle":"2025-04-20T18:47:02.836208Z","shell.execute_reply.started":"2025-04-20T18:47:02.827564Z","shell.execute_reply":"2025-04-20T18:47:02.835454Z"}},"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"203"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"df_subset['context'].str.len().max()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dDvLl2vx0a4o","outputId":"103fac31-6acf-45c6-cf69-bb1656c1fe4c","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:08.402071Z","iopub.execute_input":"2025-04-20T18:47:08.402639Z","iopub.status.idle":"2025-04-20T18:47:08.411926Z","shell.execute_reply.started":"2025-04-20T18:47:08.402617Z","shell.execute_reply":"2025-04-20T18:47:08.411378Z"}},"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"3706"},"metadata":{}}],"execution_count":100},{"cell_type":"markdown","source":"We just turn the array of the answers to a string since none have multiple answers","metadata":{"id":"6hWOoWFg1GZk"}},{"cell_type":"code","source":"df_subset['answers']= df_subset['answers'].apply(lambda x: x[0])","metadata":{"id":"rh00m5Jw0lWm","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:12.610541Z","iopub.execute_input":"2025-04-20T18:47:12.611076Z","iopub.status.idle":"2025-04-20T18:47:12.621530Z","shell.execute_reply.started":"2025-04-20T18:47:12.611043Z","shell.execute_reply":"2025-04-20T18:47:12.620855Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"df_subset['answers'].str.len().max()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoL1ZTTx0z8b","outputId":"e4736878-4cb3-4c68-df14-41efa24a60e8","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:14.249531Z","iopub.execute_input":"2025-04-20T18:47:14.250214Z","iopub.status.idle":"2025-04-20T18:47:14.259824Z","shell.execute_reply.started":"2025-04-20T18:47:14.250189Z","shell.execute_reply":"2025-04-20T18:47:14.259091Z"}},"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"202"},"metadata":{}}],"execution_count":102},{"cell_type":"markdown","source":"## Embeddings","metadata":{"id":"B_-pDASk5eOa"}},{"cell_type":"code","source":"!pip install --quiet gensim","metadata":{"id":"gBEVZxrJ5gav","outputId":"e51f32d7-1a78-4015-9a21-d4a580224374","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:48:36.725130Z","iopub.execute_input":"2025-04-20T17:48:36.725774Z","iopub.status.idle":"2025-04-20T17:48:39.734751Z","shell.execute_reply.started":"2025-04-20T17:48:36.725750Z","shell.execute_reply":"2025-04-20T17:48:39.733167Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"all_texts = (\n    df_subset['question'].tolist() +\n    df_subset['context'].tolist() +\n    df_subset['answers'].tolist()\n)\ntokenizer = Tokenizer(\n    num_words=20000,\n    oov_token='[UNK]',\n    filters='''!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'''\n)\ntokenizer.fit_on_texts(all_texts)\n\nq_seqs = tokenizer.texts_to_sequences(df_subset['question'])\nc_seqs = tokenizer.texts_to_sequences(df_subset['context'])\na_seqs = tokenizer.texts_to_sequences(df_subset['answers'])","metadata":{"id":"l2U-kh4D5mdK","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:26.140467Z","iopub.execute_input":"2025-04-20T18:47:26.141022Z","iopub.status.idle":"2025-04-20T18:47:28.081408Z","shell.execute_reply.started":"2025-04-20T18:47:26.140996Z","shell.execute_reply":"2025-04-20T18:47:28.080824Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index)\nprint(\"Total unique tokens:\", vocab_size)","metadata":{"id":"KnOdBzFlWfhR","outputId":"b7b758c5-8e84-4028-94b5-4fbd1de5fb96","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:28.588526Z","iopub.execute_input":"2025-04-20T18:47:28.588792Z","iopub.status.idle":"2025-04-20T18:47:28.592790Z","shell.execute_reply.started":"2025-04-20T18:47:28.588773Z","shell.execute_reply":"2025-04-20T18:47:28.592107Z"}},"outputs":[{"name":"stdout","text":"Total unique tokens: 57044\n","output_type":"stream"}],"execution_count":104},{"cell_type":"markdown","source":"**Load gloVe dictionary**","metadata":{"id":"bEwBdMqoGBO_"}},{"cell_type":"code","source":"def prepare_glove(target_dim=100, work_subdir='glove',\n                  input_dataset_slug='glove6b',\n                  download_url='http://nlp.stanford.edu/data/glove.6B.zip'):\n    maybe_mount_drive()\n\n    if is_kaggle():\n        work_dir = f'/kaggle/working/{work_subdir}'\n        uploaded_zip = f'/kaggle/input/{input_dataset_slug}/glove.6B.zip'\n    elif is_colab():\n        work_dir = f'/content/drive/MyDrive/{work_subdir}'\n        uploaded_zip = None\n    else:\n        work_dir = f'./data/{work_subdir}'\n        uploaded_zip = None\n\n    os.makedirs(work_dir, exist_ok=True)\n\n    target_file = f'glove.6B.{target_dim}d.txt'\n    txt_path = os.path.join(work_dir, target_file)\n    zip_path = os.path.join(work_dir, os.path.basename(download_url))\n\n    if os.path.exists(txt_path):\n        return txt_path\n\n    if is_kaggle() and uploaded_zip and os.path.exists(uploaded_zip):\n        zip_path = uploaded_zip\n    else:\n        if requests is None:\n            raise RuntimeError(\"`requests` not available; offline mode\")\n        with requests.get(download_url, stream=True) as r, open(zip_path, 'wb') as f:\n            r.raise_for_status()\n            for chunk in r.iter_content(8192):\n                f.write(chunk)\n\n    with zipfile.ZipFile(zip_path, 'r') as z:\n        z.extract(target_file, path=work_dir)\n\n    if not os.path.exists(txt_path):\n        raise RuntimeError(f\"Failed to extract {target_file}\")\n\n    return txt_path\n\n# Usage\nglove_path = prepare_glove()\nprint(\"GloVe file:\", glove_path)","metadata":{"id":"sHHCMrjhGG4V","outputId":"cc629348-918c-4ab8-85a2-0297f924a578","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:34.611454Z","iopub.execute_input":"2025-04-20T18:47:34.611988Z","iopub.status.idle":"2025-04-20T18:47:34.619607Z","shell.execute_reply.started":"2025-04-20T18:47:34.611967Z","shell.execute_reply":"2025-04-20T18:47:34.618853Z"}},"outputs":[{"name":"stdout","text":"GloVe file: /kaggle/working/glove/glove.6B.100d.txt\n","output_type":"stream"}],"execution_count":105},{"cell_type":"markdown","source":"**Creating embeddings index (mapping words to vectors)**","metadata":{"id":"moKmgC0MGTU0"}},{"cell_type":"code","source":"embeddings_index = {}\nwith open(glove_path, 'r', encoding='utf-8') as f:\n    for line in f:\n        parts = line.rstrip().split(\" \")\n        word = parts[0]\n        vec  = np.asarray(parts[1:], dtype='float32')\n        embeddings_index[word] = vec","metadata":{"id":"3cSrFo3eGdH8","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:38.660686Z","iopub.execute_input":"2025-04-20T18:47:38.660957Z","iopub.status.idle":"2025-04-20T18:47:46.607775Z","shell.execute_reply.started":"2025-04-20T18:47:38.660937Z","shell.execute_reply":"2025-04-20T18:47:46.607241Z"}},"outputs":[],"execution_count":106},{"cell_type":"markdown","source":"**Creating our look-up table (embedding matrix)**","metadata":{"id":"DWBBEfnDHXhb"}},{"cell_type":"code","source":"vocab_size = 20000\nemb_dim = 100\nembedding_matrix = np.random.normal(size=(vocab_size, emb_dim)) * 0.01","metadata":{"id":"KNj69dr19Io_","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:46.608815Z","iopub.execute_input":"2025-04-20T18:47:46.609067Z","iopub.status.idle":"2025-04-20T18:47:46.676879Z","shell.execute_reply.started":"2025-04-20T18:47:46.609037Z","shell.execute_reply":"2025-04-20T18:47:46.676317Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"for word, idx in tokenizer.word_index.items():\n    if idx >= vocab_size:\n        continue\n    if word in embeddings_index:\n        embedding_matrix[idx] = embeddings_index[word]","metadata":{"id":"5OFnRaWp_DsR","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:46.677636Z","iopub.execute_input":"2025-04-20T18:47:46.677895Z","iopub.status.idle":"2025-04-20T18:47:46.719927Z","shell.execute_reply.started":"2025-04-20T18:47:46.677874Z","shell.execute_reply":"2025-04-20T18:47:46.719376Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"word = tokenizer.index_word[2]\nprint(word)\nprint(embedding_matrix[2])","metadata":{"id":"IkAwXryuJNZU","outputId":"029f918a-608f-452d-f6f6-ac58b7ee8b45","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:47.082046Z","iopub.execute_input":"2025-04-20T18:47:47.082613Z","iopub.status.idle":"2025-04-20T18:47:47.087156Z","shell.execute_reply.started":"2025-04-20T18:47:47.082590Z","shell.execute_reply":"2025-04-20T18:47:47.086528Z"}},"outputs":[{"name":"stdout","text":"the\n[-0.038194   -0.24487001  0.72812003 -0.39961001  0.083172    0.043953\n -0.39140999  0.3344     -0.57545     0.087459    0.28786999 -0.06731\n  0.30906001 -0.26383999 -0.13231    -0.20757     0.33395001 -0.33848\n -0.31742999 -0.48335999  0.1464     -0.37303999  0.34577     0.052041\n  0.44946    -0.46970999  0.02628    -0.54154998 -0.15518001 -0.14106999\n -0.039722    0.28277001  0.14393     0.23464    -0.31020999  0.086173\n  0.20397     0.52623999  0.17163999 -0.082378   -0.71787    -0.41531\n  0.20334999 -0.12763     0.41367     0.55186999  0.57907999 -0.33476999\n -0.36559001 -0.54856998 -0.062892    0.26583999  0.30204999  0.99774998\n -0.80480999 -3.0243001   0.01254    -0.36941999  2.21670008  0.72201002\n -0.24978     0.92136002  0.034514    0.46744999  1.10790002 -0.19358\n -0.074575    0.23353    -0.052062   -0.22044     0.057162   -0.15806\n -0.30798    -0.41624999  0.37972     0.15006    -0.53211999 -0.20550001\n -1.25259995  0.071624    0.70564997  0.49744001 -0.42063001  0.26148\n -1.53799999 -0.30223    -0.073438   -0.28312001  0.37103999 -0.25217\n  0.016215   -0.017099   -0.38984001  0.87423998 -0.72569001 -0.51058\n -0.52028    -0.1459      0.82779998  0.27061999]\n","output_type":"stream"}],"execution_count":109},{"cell_type":"markdown","source":"**Create embedding layer**","metadata":{"id":"fXmVw1ItJ-uQ"}},{"cell_type":"code","source":"embedding_layer = Embedding(\n    input_dim=vocab_size,\n    output_dim=emb_dim,\n    weights=[embedding_matrix],\n    mask_zero=True,\n    trainable=False,\n    name='glove_embedding'\n)","metadata":{"id":"FVUoVwpZJPMt","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:49.611517Z","iopub.execute_input":"2025-04-20T18:47:49.611774Z","iopub.status.idle":"2025-04-20T18:47:49.633838Z","shell.execute_reply.started":"2025-04-20T18:47:49.611754Z","shell.execute_reply":"2025-04-20T18:47:49.633344Z"}},"outputs":[],"execution_count":110},{"cell_type":"markdown","source":"## Phase One","metadata":{"id":"Ci0NXaY-UBOi"}},{"cell_type":"code","source":"MAX_Q_LEN   = df_subset['question'].str.len().max()\nMAX_A_LEN   = df_subset['answers'].str.len().max()\nVOCAB_SIZE  = 20000\nEMB_DIM     = embedding_matrix.shape[1]\nUNITS       = 128\nBATCH_SIZE  = 64\nEPOCHS      = 30","metadata":{"id":"XSOJYRpOKaqa","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:47:51.330582Z","iopub.execute_input":"2025-04-20T18:47:51.331123Z","iopub.status.idle":"2025-04-20T18:47:51.343308Z","shell.execute_reply.started":"2025-04-20T18:47:51.331094Z","shell.execute_reply":"2025-04-20T18:47:51.342603Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"q_padded = pad_sequences(q_seqs, maxlen=MAX_Q_LEN, padding='post', truncating='post')\na_padded = pad_sequences(a_seqs, maxlen=MAX_A_LEN, padding='post', truncating='post')","metadata":{"id":"JERoPRt-RHlC","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:48:30.801266Z","iopub.execute_input":"2025-04-20T18:48:30.801519Z","iopub.status.idle":"2025-04-20T18:48:30.847003Z","shell.execute_reply.started":"2025-04-20T18:48:30.801501Z","shell.execute_reply":"2025-04-20T18:48:30.846287Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"decoder_input  = a_padded[:, :-1]\ndecoder_target = a_padded[:, 1:]\n\nXq_tr, Xq_val, Din_tr, Din_val, Dt_tr, Dt_val = train_test_split(\n    q_padded, decoder_input, decoder_target,\n    test_size=0.1, random_state=42\n)\n\ndef make_ds(q, d_in, d_tar, batch_size=32):\n    mask = tf.cast(tf.not_equal(d_tar, 0), tf.float32)\n    ds = tf.data.Dataset.from_tensor_slices(\n        ((q, d_in), d_tar, mask)\n    )\n    return ds.shuffle(2000).batch(batch_size).prefetch(1)\n\ntrain_ds = make_ds(Xq_tr, Din_tr, Dt_tr, batch_size=BATCH_SIZE)\nval_ds   = make_ds(Xq_val, Din_val, Dt_val, batch_size=BATCH_SIZE)","metadata":{"id":"zaezBfWvSmaO","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:49:02.490713Z","iopub.execute_input":"2025-04-20T18:49:02.491374Z","iopub.status.idle":"2025-04-20T18:49:02.531575Z","shell.execute_reply.started":"2025-04-20T18:49:02.491353Z","shell.execute_reply":"2025-04-20T18:49:02.530990Z"}},"outputs":[],"execution_count":118},{"cell_type":"code","source":"print(\"Train batches:\", tf.data.experimental.cardinality(train_ds).numpy())\nprint(\"Val   batches:\", tf.data.experimental.cardinality(val_ds).numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:49:15.818308Z","iopub.execute_input":"2025-04-20T18:49:15.818550Z","iopub.status.idle":"2025-04-20T18:49:15.823391Z","shell.execute_reply.started":"2025-04-20T18:49:15.818535Z","shell.execute_reply":"2025-04-20T18:49:15.822734Z"}},"outputs":[{"name":"stdout","text":"Train batches: 141\nVal   batches: 16\n","output_type":"stream"}],"execution_count":119},{"cell_type":"markdown","source":"**Building the model**","metadata":{"id":"s-DjaB2H1448"}},{"cell_type":"code","source":"class Seq2SeqLSTM(tf.keras.Model):\n    def __init__(self,vocab_size,emb_dim,units,max_q_len,max_a_len,embedding_matrix=None,pad_token_id=0,**kwargs):\n        super().__init__(**kwargs)\n        self.pad_token_id = pad_token_id\n\n\n        if embedding_matrix is not None:\n            self.embedding = Embedding(vocab_size, emb_dim,weights=[embedding_matrix],trainable=False,mask_zero=True)\n        else:\n            self.embedding = Embedding(vocab_size, emb_dim,mask_zero=True)\n\n        #units is the vector size of the hidden state\n        #return_state if true returns the final h and c\n        self.encoder_lstm = LSTM(units, return_state=True, name='encoder_lstm')\n\n        #return sequence returns all the hidden states from h_1 to h_n\n        #return sequence is for evaluation\n        #return state is for inference because after each token generated we need to feed the model the states again\n        self.decoder_lstm = LSTM(units,return_sequences=True,return_state=True, name='decoder_lstm')\n\n        #the layer needed to predict the next word\n        self.dense = Dense(vocab_size, activation='softmax', name='decoder_dense')\n\n    def call(self, inputs, training=False):\n        encoder_inputs, decoder_inputs = inputs\n\n        x_enc = self.embedding(encoder_inputs)\n        _, state_h, state_c = self.encoder_lstm(x_enc, training=training)\n        encoder_states = [state_h, state_c]\n\n        x_dec = self.embedding(decoder_inputs)\n        dec_outputs, _, _ = self.decoder_lstm(x_dec, initial_state=encoder_states, training=training)\n        return self.dense(dec_outputs)\n\n    # def compute_masked_accuracy(self, y_true, y_pred):\n    #     pad = self.pad_token_id\n    #     y_pred_id = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n    #     y_true    = tf.cast(y_true, tf.int32)\n    #     mask      = tf.cast(tf.not_equal(y_true, pad), tf.float32)\n    #     matches   = tf.cast(tf.equal(y_true, y_pred_id), tf.float32) * mask\n    #     return tf.reduce_sum(matches) / tf.reduce_sum(mask)\n","metadata":{"id":"XONLiGcUxUgA","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:49:40.218968Z","iopub.execute_input":"2025-04-20T18:49:40.219622Z","iopub.status.idle":"2025-04-20T18:49:40.225801Z","shell.execute_reply.started":"2025-04-20T18:49:40.219599Z","shell.execute_reply":"2025-04-20T18:49:40.225175Z"}},"outputs":[],"execution_count":121},{"cell_type":"code","source":"model = Seq2SeqLSTM( vocab_size=vocab_size,\n                    emb_dim=100,units=128,\n                     max_q_len=MAX_Q_LEN,max_a_len=MAX_A_LEN,embedding_matrix=embedding_matrix,pad_token_id=0)\n\ndummy_q = tf.zeros((1, MAX_Q_LEN), dtype=tf.int32)\ndummy_a = tf.zeros((1, MAX_A_LEN-1), dtype=tf.int32)\n_ = model((dummy_q, dummy_a))\nprint(\"Mask on encoder:\", model.embedding.compute_mask(dummy_q).numpy())\nprint(\"Mask on decoder:\", model.embedding.compute_mask(dummy_a).numpy())","metadata":{"id":"vGm4vS0uUC-p","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:49:41.766223Z","iopub.execute_input":"2025-04-20T18:49:41.766976Z","iopub.status.idle":"2025-04-20T18:49:42.838681Z","shell.execute_reply.started":"2025-04-20T18:49:41.766951Z","shell.execute_reply":"2025-04-20T18:49:42.838074Z"}},"outputs":[{"name":"stdout","text":"Mask on encoder: [[False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False]]\nMask on decoder: [[False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False False False False\n  False False False False False False False False False]]\n","output_type":"stream"}],"execution_count":122},{"cell_type":"code","source":"model.compile(\n  optimizer='adam',\n  loss='sparse_categorical_crossentropy',\n  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n)\nmodel.summary()","metadata":{"id":"WY8ot7KK74I-","outputId":"b3a84da1-e1f8-44e5-8cdf-ba203079b9be","colab":{"base_uri":"https://localhost:8080/","height":289},"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:49:43.811875Z","iopub.execute_input":"2025-04-20T18:49:43.812394Z","iopub.status.idle":"2025-04-20T18:49:43.831529Z","shell.execute_reply.started":"2025-04-20T18:49:43.812372Z","shell.execute_reply":"2025-04-20T18:49:43.830987Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"seq2_seq_lstm_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"seq2_seq_lstm_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m2,000,000\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)                  │ ((\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;34m1\u001b[0m,    │         \u001b[38;5;34m117,248\u001b[0m │\n│                                      │ \u001b[38;5;34m128\u001b[0m))                       │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)                  │ ((\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m201\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m),   │         \u001b[38;5;34m117,248\u001b[0m │\n│                                      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m))                   │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ decoder_dense (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m201\u001b[0m, \u001b[38;5;34m20000\u001b[0m)             │       \u001b[38;5;34m2,580,000\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>))                       │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n│                                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>))                   │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ decoder_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,000</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,814,496\u001b[0m (18.37 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,814,496</span> (18.37 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,814,496\u001b[0m (10.74 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,814,496</span> (10.74 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,000,000\u001b[0m (7.63 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> (7.63 MB)\n</pre>\n"},"metadata":{}}],"execution_count":123},{"cell_type":"code","source":"!mkdir /content/drive/MyDrive/models","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36vdUH2M4TGY","outputId":"28b9f184-420b-4feb-f9fb-ce4118b6f98c","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:56:32.784404Z","iopub.status.idle":"2025-04-20T17:56:32.784607Z","shell.execute_reply.started":"2025-04-20T17:56:32.784506Z","shell.execute_reply":"2025-04-20T17:56:32.784514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MODEL_DIR = get_model_dir()\nCHECKPOINT_PATH = os.path.join(MODEL_DIR, 'seq2seq_lstm_best.keras')\n\ncheckpoint_cb = ModelCheckpoint(\n    filepath=CHECKPOINT_PATH,\n    monitor='val_sparse_categorical_accuracy',\n    save_best_only=True,\n    mode='max',\n    verbose=1\n)\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n    callbacks=[checkpoint_cb]\n)\nprint(f\"Best model will be saved to: {CHECKPOINT_PATH}\")","metadata":{"id":"C9i5PQ0q8AhI","outputId":"32a5b44e-efa3-4617-cb3a-fac519494bfc","colab":{"base_uri":"https://localhost:8080/","height":211},"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:02.474470Z","iopub.execute_input":"2025-04-20T18:50:02.474751Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 6.0401 - sparse_categorical_accuracy: 5.6337e-04\nEpoch 1: val_sparse_categorical_accuracy improved from -inf to 0.00074, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 135ms/step - loss: 6.0374 - sparse_categorical_accuracy: 5.6404e-04 - val_loss: 5.2732 - val_sparse_categorical_accuracy: 7.3981e-04\nEpoch 2/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 4.9210 - sparse_categorical_accuracy: 8.3332e-04\nEpoch 2: val_sparse_categorical_accuracy improved from 0.00074 to 0.00087, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 131ms/step - loss: 4.9216 - sparse_categorical_accuracy: 8.3354e-04 - val_loss: 5.3581 - val_sparse_categorical_accuracy: 8.6891e-04\nEpoch 3/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 4.8420 - sparse_categorical_accuracy: 9.9294e-04\nEpoch 3: val_sparse_categorical_accuracy improved from 0.00087 to 0.00109, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - loss: 4.8425 - sparse_categorical_accuracy: 9.9317e-04 - val_loss: 5.3723 - val_sparse_categorical_accuracy: 0.0011\nEpoch 4/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 4.7895 - sparse_categorical_accuracy: 0.0011\nEpoch 4: val_sparse_categorical_accuracy improved from 0.00109 to 0.00116, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - loss: 4.7897 - sparse_categorical_accuracy: 0.0011 - val_loss: 5.3440 - val_sparse_categorical_accuracy: 0.0012\nEpoch 5/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 4.6891 - sparse_categorical_accuracy: 0.0012\nEpoch 5: val_sparse_categorical_accuracy improved from 0.00116 to 0.00126, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - loss: 4.6893 - sparse_categorical_accuracy: 0.0012 - val_loss: 5.3331 - val_sparse_categorical_accuracy: 0.0013\nEpoch 6/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 4.5802 - sparse_categorical_accuracy: 0.0012\nEpoch 6: val_sparse_categorical_accuracy improved from 0.00126 to 0.00131, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - loss: 4.5805 - sparse_categorical_accuracy: 0.0012 - val_loss: 5.3414 - val_sparse_categorical_accuracy: 0.0013\nEpoch 7/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 4.5100 - sparse_categorical_accuracy: 0.0013\nEpoch 7: val_sparse_categorical_accuracy improved from 0.00131 to 0.00134, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - loss: 4.5099 - sparse_categorical_accuracy: 0.0013 - val_loss: 5.3168 - val_sparse_categorical_accuracy: 0.0013\nEpoch 8/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 4.4037 - sparse_categorical_accuracy: 0.0014\nEpoch 8: val_sparse_categorical_accuracy improved from 0.00134 to 0.00140, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - loss: 4.4036 - sparse_categorical_accuracy: 0.0014 - val_loss: 5.3267 - val_sparse_categorical_accuracy: 0.0014\nEpoch 9/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 4.2529 - sparse_categorical_accuracy: 0.0015\nEpoch 9: val_sparse_categorical_accuracy improved from 0.00140 to 0.00146, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - loss: 4.2530 - sparse_categorical_accuracy: 0.0015 - val_loss: 5.2806 - val_sparse_categorical_accuracy: 0.0015\nEpoch 10/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 4.1400 - sparse_categorical_accuracy: 0.0015\nEpoch 10: val_sparse_categorical_accuracy improved from 0.00146 to 0.00148, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - loss: 4.1400 - sparse_categorical_accuracy: 0.0015 - val_loss: 5.3194 - val_sparse_categorical_accuracy: 0.0015\nEpoch 11/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 4.0355 - sparse_categorical_accuracy: 0.0015\nEpoch 11: val_sparse_categorical_accuracy did not improve from 0.00148\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 130ms/step - loss: 4.0354 - sparse_categorical_accuracy: 0.0015 - val_loss: 5.2903 - val_sparse_categorical_accuracy: 0.0014\nEpoch 12/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 3.9198 - sparse_categorical_accuracy: 0.0016\nEpoch 12: val_sparse_categorical_accuracy improved from 0.00148 to 0.00150, saving model to /kaggle/working/models/seq2seq_lstm_best.keras\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 132ms/step - loss: 3.9197 - sparse_categorical_accuracy: 0.0016 - val_loss: 5.3597 - val_sparse_categorical_accuracy: 0.0015\nEpoch 13/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 3.8141 - sparse_categorical_accuracy: 0.0016\nEpoch 13: val_sparse_categorical_accuracy did not improve from 0.00150\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 130ms/step - loss: 3.8140 - sparse_categorical_accuracy: 0.0016 - val_loss: 5.3494 - val_sparse_categorical_accuracy: 0.0015\nEpoch 14/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 3.6773 - sparse_categorical_accuracy: 0.0016\nEpoch 14: val_sparse_categorical_accuracy did not improve from 0.00150\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 131ms/step - loss: 3.6773 - sparse_categorical_accuracy: 0.0016 - val_loss: 5.3758 - val_sparse_categorical_accuracy: 0.0015\nEpoch 15/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 3.5737 - sparse_categorical_accuracy: 0.0017\nEpoch 15: val_sparse_categorical_accuracy did not improve from 0.00150\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 130ms/step - loss: 3.5736 - sparse_categorical_accuracy: 0.0017 - val_loss: 5.3679 - val_sparse_categorical_accuracy: 0.0015\nEpoch 16/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 3.4294 - sparse_categorical_accuracy: 0.0018\nEpoch 16: val_sparse_categorical_accuracy did not improve from 0.00150\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 130ms/step - loss: 3.4294 - sparse_categorical_accuracy: 0.0018 - val_loss: 5.4243 - val_sparse_categorical_accuracy: 0.0015\nEpoch 17/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 3.3432 - sparse_categorical_accuracy: 0.0018","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}